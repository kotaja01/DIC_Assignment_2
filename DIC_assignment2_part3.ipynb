{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab4638a-963d-444d-9386-2b872a6654e8",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f466f5-7d91-40a3-a8a4-6e5174792445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.feature import (\n",
    "\n",
    "    ChiSqSelector,\n",
    "\n",
    "    RegexTokenizer,\n",
    "\n",
    "    StringIndexer,\n",
    "\n",
    "    IDF,\n",
    "\n",
    "    StopWordsRemover,\n",
    "\n",
    "    CrossValidator,\n",
    "\n",
    "    Normalizer,\n",
    "\n",
    "    CountVectorizer,\n",
    "\n",
    "    HashingTF,\n",
    "\n",
    "    ChiSqSelector,\n",
    "\n",
    "    Normalizer,\n",
    "\n",
    "    StandardScaler,\n",
    "    UnivariateFeatureSelector,\n",
    "\n",
    ")\n",
    "\n",
    "from pyspark.ml.tuning import (\n",
    "\n",
    "    ParamGridBuilder,\n",
    "\n",
    "    TrainValidationSplit,\n",
    "\n",
    "    TrainValidationSplitModel,\n",
    "\n",
    ")\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace, split, col, udf\n",
    "\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b03697-8b75-4a7b-b6f7-6481d5d97b38",
   "metadata": {},
   "source": [
    "# File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef005730-a85f-4882-a6f9-7021f4b15335",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file_path = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "full_file_path = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviewscombined.json\"\n",
    "\n",
    "output_file_path = \"output_assignment2.txt\"\n",
    "\n",
    "stop_words_path = \"stopwords.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed6e28-3506-4da5-af36-743936392f3f",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4041d5d4-00a8-4c83-ac7f-68f9681fdc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/05/04 10:34:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/04 10:34:32 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/05/04 10:34:32 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/05/04 10:34:32 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/05/04 10:34:32 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "25/05/04 10:34:32 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "25/05/04 10:34:32 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Assignment_2_session\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1bdf5",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008a67fb-fde9-4259-98e2-f7ebe9d6c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = spark.read.json(dev_file_path)\n",
    "df = df_full.select(\"reviewText\", \"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ac89f-bceb-42ef-9713-1ee2b4998dfd",
   "metadata": {},
   "source": [
    "# Code Taken from Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a695e-6be8-4f13-8903-b716645b56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define udf\n",
    "@udf(returnType=StringType())\n",
    "def casefold_text(text):\n",
    "    if text is not None:\n",
    "        return text.casefold()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Create a custom casefolder\n",
    "class CasefoldTransformer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def __init__(self, inputCol=\"text\", outputCol=\"casefolded_text\"):\n",
    "        super(CasefoldTransformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, df):\n",
    "        return df.withColumn(self.outputCol, casefold_text(df[self.inputCol]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d724eb-2fe4-47bd-83e3-0fca78610f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(stop_words_path, \"r\") as stop_words_file:\n",
    "    stop_words = list(stop_words_file.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5550b5-7f07-4e58-919e-e12108b880ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "casefolder = CasefoldTransformer(\n",
    "    inputCol=\"reviewText\", outputCol=\"reviewText_casefolded\"\n",
    ")\n",
    "\n",
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"reviewText_casefolded\",\n",
    "    outputCol=\"tokens\",\n",
    "    pattern=\"[ \\t\\d\\(\\)\\[\\]\\{\\}\\.\\!\\?,;:+=\\-_'\\\"`~#@&\\*\\%€\\$§\\\\/]+\",\n",
    "    gaps=True,\n",
    "    toLowercase=False,\n",
    ")\n",
    "\n",
    "remover = StopWordsRemover(\n",
    "    inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=stop_words\n",
    ")\n",
    "\n",
    "tf = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"rawFeatures\")\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"category_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b302a3c-a8a9-4ad8-827e-fb9d91188512",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53889494-8d30-4fd0-8781-06e732ccb928",
   "metadata": {},
   "source": [
    " In this part, you will train a text classifier from the features extracted in Part 2. The goal is to train a model that\n",
    " can predict the product category from a review's text.  To this end, extend the pipeline from Part 2 such that a Support Vector Machine classifier is trained. Since\n",
    " we are dealing with multi-class problems, make sure to put a strategy in place that allows binary classifiers to\n",
    " be applicable. Apply vector length normalization before feeding the feature vectors into the classifier (use\n",
    " Normalizer with L2 norm).  Follow best practices for ML experiment design and investigate the effects of parameter settings using the\n",
    " functions provided by Spark:\n",
    " -  Split the review data into training, validation, and test set.\n",
    " - Make experiments reproducible.\n",
    " - Use a grid search for parameter optimization:\n",
    " Compare chi square overall top 2000 filtered features with another, heavier filtering with much\n",
    " less dimensionality (see Spark ML documentation for options).\n",
    "\n",
    "\n",
    " - Compare different SVM settings by varying the regularization parameter (choose 3 different\n",
    " values), standardization of training features (2 values), and maximum number of iterations (2\n",
    " values).\n",
    " Use the MulticlassClassificationEvaluator to estimate performance of your trained\n",
    " classifiers on the test set, using F1 measure as criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fe841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to not overload the server we did gridsearch on a 10% subset of the dev data\n",
    "df_sampled = df.sample(withReplacement=False, fraction=0.1, seed=42)\n",
    "df_sampled.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124034a-113b-4de0-8c40-4e72785d2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector length normalization L2 Norm\n",
    "normalizer = Normalizer(inputCol=\"selectedFeatures\", outputCol=\"normalizedFeatures\")\n",
    "\n",
    "# add scaler\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"selectedFeatures\", outputCol=\"scaledFeatures\", withMean=False\n",
    ")\n",
    "\n",
    "# setup SVM\n",
    "svm = LinearSVC(featuresCol=\"normalizedFeatures\", labelCol=\"category_index\")\n",
    "\n",
    "# to allow binary classification, we use a one-vs-all classifier\n",
    "ova = OneVsRest(\n",
    "    classifier=svm,\n",
    "    featuresCol=\"normalizedFeatures\",\n",
    "    labelCol=\"category_index\",\n",
    "    parallelism=4,  # we use parallelism = 4 to not overload the server\n",
    ")\n",
    "\n",
    "# split data into train, validation, test, adding a seed to make it reproucible\n",
    "train_data_sampled, validation_data_sampled, test_data_sampled = df_sampled.randomSplit(\n",
    "    [0.6, 0.2, 0.2], seed=1\n",
    ")  # for the gridsearch\n",
    "train_data, validation_data, test_data = df.randomSplit(\n",
    "    [0.6, 0.2, 0.2], seed=1\n",
    ")  # for final model application\n",
    "\n",
    "# evaluator\n",
    "f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"category_index\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# we try 2 selectors, one from task 2 and one more with heavier filtering\n",
    "selectors = [\n",
    "    ChiSqSelector(\n",
    "        numTopFeatures=2000,\n",
    "        featuresCol=\"features\",\n",
    "        outputCol=\"selectedFeatures\",\n",
    "        labelCol=\"category_index\",\n",
    "    ),\n",
    "    UnivariateFeatureSelector(\n",
    "        selectionMode=\"numTopFeatures\",\n",
    "        labelCol=\"category_index\",\n",
    "        featuresCol=\"features\",\n",
    "        outputCol=\"selectedFeatures\",\n",
    "    )\n",
    "    .setFeatureType(\"categorical\")\n",
    "    .setLabelType(\"categorical\")\n",
    "    .setSelectionThreshold(100), #number of top features\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32774ef0-3a00-43e8-9c32-a24405d1f028",
   "metadata": {},
   "source": [
    "# grid search:\n",
    "- chi square overall top 2000 filtered features\n",
    "- different SVM settings by varying the regularization parameter (choose 3 different values)\n",
    "- standardization of training features (2 values)\n",
    "- maximum number of iterations (2 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad404d08-2efc-4193-8253-88ece7b2a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(svm.regParam, [0.01, 0.1, 1])\n",
    "    .addGrid(svm.maxIter, [100, 500])\n",
    "    .addGrid(svm.standardization, [True, False])\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d346a65",
   "metadata": {},
   "source": [
    "To not overload server, the loop was unrolled and the different combinations were applied one after another.\n",
    "But to keep things structured, we want to hand in the looped code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac4074-bd99-4208-b2c4-bbc3ae69c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {Param(parent='LinearSVC_36bf267fccea', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LinearSVC_36bf267fccea', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='StandardScaler_5680ee9c641b', name='withMean', doc='Center data with mean'): False}, F1 Score: 0.6028949592378424\n",
      "Params: {Param(parent='LinearSVC_36bf267fccea', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LinearSVC_36bf267fccea', name='maxIter', doc='max number of iterations (>= 0).'): 5, Param(parent='StandardScaler_5680ee9c641b', name='withMean', doc='Center data with mean'): True}, F1 Score: 0.6025472627023611\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_f1_score = 0\n",
    "best_model = None\n",
    "\n",
    "for selector in selectors: #iterate through selectors\n",
    "    print(f\"\\nEvaluating selector with top {selector.getNumTopFeatures()} features\\n\" + \"-\"*50)\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        stages=[\n",
    "            casefolder,\n",
    "            tokenizer,\n",
    "            remover,\n",
    "            indexer,\n",
    "            tf,\n",
    "            idf,\n",
    "            selector,\n",
    "            scaler,\n",
    "            normalizer,\n",
    "            ova,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for params in paramGrid:\n",
    "        model = pipeline.copy(params).fit(train_data_sampled)\n",
    "        predictions = model.transform(validation_data_sampled)\n",
    "        f1_score = f1.evaluate(predictions)\n",
    "\n",
    "        print(f\"Selector top {selector.getNumTopFeatures()}, Params: {params}, F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "        if f1_score > best_f1_score:\n",
    "            best_f1_score = f1_score\n",
    "            best_model = model\n",
    "            best_selector = selector\n",
    "            best_params = params\n",
    "\n",
    "print(f\"\\nBest Validation F1 Score: {best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760f645",
   "metadata": {},
   "source": [
    "# Applying the best model on the full dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baecb1b-a7a2-44ae-9c73-53d94059b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Running: regParam=0.1, maxIter=100, standardization=True\")\n",
    "final_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        casefolder,\n",
    "        tokenizer,\n",
    "        remover,\n",
    "        indexer,\n",
    "        tf,\n",
    "        idf,\n",
    "        best_selector,\n",
    "        scaler,\n",
    "        normalizer,\n",
    "        ova,\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_model = final_pipeline.copy(best_params).fit(train_data)\n",
    "pred = final_model.transform(validation_data)\n",
    "f1_score = f1.evaluate(pred)\n",
    "print(f\"Final model F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ed744-841f-4005-a4f4-6062079d7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(\"best_svm_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
